{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data , housing_prices  = load_boston(return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prediction error [21.89777922]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11080.27628415])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to define w_Tilde, our X is our data augmented by one and Y is our housing prices \n",
    "n = len(data)\n",
    "m = len(housing_prices)\n",
    "def least_squared(housing_prices,data):\n",
    "    \n",
    "    features = np.column_stack((data,np.ones((506,1))))\n",
    "    Y = housing_prices.reshape(506,1)\n",
    "    #W_Tilde is defined as (X^TX)^-1*X^T*Y\n",
    "    W_Tilde = np.linalg.inv(features.T @ features) @ features.T @ Y\n",
    "   # print (W_Tilde.shape)\n",
    "    #Now we need to define Yi as Xi.T @ w_Tilde\n",
    "    Y_hat = features @ W_Tilde\n",
    "   # print (Y_hat.shape)\n",
    "   # print (Y.shape)\n",
    "    sum = 0\n",
    "    #We then calulate the error by running a for loop of (Y-Y_hat)^2\n",
    "    for i in range(506):\n",
    "        sum = sum +((Y[i]-Y_hat[i])**2)\n",
    "    print(\"Average prediction error\" , sum/506) #Average prediction error\n",
    "    return sum\n",
    "least_squared(housing_prices,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-fde6f8a9b903>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merror_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mResult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCross_Validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing_prices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The error is \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The average from the CV is \"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-fde6f8a9b903>\u001b[0m in \u001b[0;36mCross_Validation\u001b[1;34m(housing_prices, data)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtraining_prices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle_housing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mindex1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle_housing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m506\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleast_squared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_prices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0maugmented_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmented_data\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-28aa46e9ae17>\u001b[0m in \u001b[0;36mleast_squared\u001b[1;34m(housing_prices, data)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mleast_squared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing_prices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m506\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhousing_prices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m506\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#W_Tilde is defined as (X^TX)^-1*X^T*Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "# We now need to implement the 5-fold cross validation\n",
    "# We will need to do 5k-fold cross validation\n",
    "#Essentially what K-fold is, is running Least squared in a for loop 5 times using a training sets\n",
    "#We have 506 samples, so we need to have 506/5 ~= 101 samples per run\n",
    "def Cross_Validation(housing_prices,data):\n",
    "    #First before we do k-fold we need to shuffle the data\n",
    "    joined = np.concatenate((data,Y),axis = 1)\n",
    "    np.random.shuffle(joined)\n",
    "    shuffle_data = joined.T[0:13].T # We have 13 variables\n",
    "    shuffle_housing_prices=joined[:,13]\n",
    "    error_array = []\n",
    "    #Next we do the k-fold where k=5\n",
    "    for k in range (0,5):\n",
    "        if(k==4):\n",
    "            # make indexes that will be the number of our samples\n",
    "            index1 = 404\n",
    "            index2 = 506\n",
    "        else: \n",
    "            index1 = (k*101)\n",
    "            index2 = index1+101\n",
    "        # We know announce the test set and the training set\n",
    "        test_data = shuffle_data[index1:index2]\n",
    "        test_prices = shuffle_housing_prices[index1:index2]\n",
    "        training_data = np.concatenate((shuffle_data[0:index1],shuffle_data[index2:506]))\n",
    "        training_prices = np.concatenate((shuffle_housing_prices[0:index1],shuffle_housing_prices[index2:506]))\n",
    "            \n",
    "        W = least_squared(training_prices,training_data)\n",
    "        augmented_data = np.concatenate((data,np.ones((data.shape[0],1))),axis=1)\n",
    "        output = augmented_data @ W\n",
    "        Labels = np.reshape(test_prices,(output.shape[0],1))\n",
    "        difference = np.linalg.norm(output-labels,2)\n",
    "        error_array.append((difference**2)/output.shape[0])\n",
    "            \n",
    "        # Plot the data\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        x = list(*zip(output.tolist()))\n",
    "        y = list(*zip(labels.tolist()))\n",
    "        ax.scatter(y[0],x[0],c='k')\n",
    "        ax.plot(np.arange(output.shape[0]),np.arange(output.shape[0]), 'r')\n",
    "        plt.title('K-Fold Cross Validation, k='+str(k+1));\n",
    "        ax.set_xlabel('Measured')\n",
    "        ax.set_ylabel('Predicted')\n",
    "        \n",
    "    return error_array\n",
    "Result = Cross_Validation(housing_prices,data)\n",
    "print(\"The error is \", Result)\n",
    "print(\"The average from the CV is \" , mean(output))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
